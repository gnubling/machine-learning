{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Digits data set, data shape =  (1797, 64)\n",
      "[[  0.   0.   5. ...,   0.   0.   0.]\n",
      " [  0.   0.   0. ...,  10.   0.   0.]\n",
      " [  0.   0.   0. ...,  16.   9.   0.]\n",
      " ..., \n",
      " [  0.   0.   1. ...,   6.   0.   0.]\n",
      " [  0.   0.   2. ...,  12.   0.   0.]\n",
      " [  0.   0.  10. ...,  12.   1.   0.]]\n"
     ]
    }
   ],
   "source": [
    "#show plate in the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# Standard scientific Python imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.linalg\n",
    "\n",
    "# Import datasets, classifiers and performance metrics\n",
    "from sklearn import datasets, metrics, svm, neighbors, linear_model\n",
    "\n",
    "# Import Counter\n",
    "from collections import Counter\n",
    "\n",
    "# The digits dataset\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "print (\"Digits data set, data shape = \", digits.data.shape)\n",
    "print(digits.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first item as 8x8 array - represents value  0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPYAAAD7CAYAAABZjGkWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQv8HNKm2kfINTK4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x104a9b588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[  0.,   0.,   5.,  13.,   9.,   1.,   0.,   0.],\n",
       "       [  0.,   0.,  13.,  15.,  10.,  15.,   5.,   0.],\n",
       "       [  0.,   3.,  15.,   2.,   0.,  11.,   8.,   0.],\n",
       "       [  0.,   4.,  12.,   0.,   0.,   8.,   8.,   0.],\n",
       "       [  0.,   5.,   8.,   0.,   0.,   9.,   8.,   0.],\n",
       "       [  0.,   4.,  11.,   0.,   1.,  12.,   7.,   0.],\n",
       "       [  0.,   2.,  14.,   5.,  10.,  12.,   0.,   0.],\n",
       "       [  0.,   0.,   6.,  13.,  10.,   0.,   0.,   0.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (\"first item as 8x8 array - represents value \", digits.target[0])\n",
    "plt.imshow(digits.images[0], cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "plt.show()\n",
    "\n",
    "# to see the array\n",
    "digits.images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print' (<ipython-input-3-976d6eb5caaf>, line 19)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-976d6eb5caaf>\"\u001b[0;36m, line \u001b[0;32m19\u001b[0m\n\u001b[0;31m    print n_samples\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m Missing parentheses in call to 'print'\n"
     ]
    }
   ],
   "source": [
    "# The data that we are interested in is made of 8x8 images of digits, let's\n",
    "# have a look at the first 3 images, stored in the `images` attribute of the\n",
    "# dataset.  If we were working from image files, we could load them using\n",
    "# pylab.imread.  Note that each image must have the same size. For these\n",
    "# images, we know which digit they represent: it is given in the 'target' of\n",
    "# the dataset.\n",
    "images_and_labels = list(zip(digits.images, digits.target))\n",
    "for index, (image, label) in enumerate(images_and_labels[:4]):\n",
    "    plt.subplot(2, 4, index + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('Training: %i' % label)\n",
    "\n",
    "# To apply a classifier on this data, we need to flatten the image, to\n",
    "# turn the data in a (samples, feature) matrix:\n",
    "n_samples = len(digits.images)\n",
    "data = digits.images.reshape((n_samples, -1))\n",
    "\n",
    "print n_samples\n",
    "\n",
    "print len(data)\n",
    "\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "898\n",
      "Classification report for k = 1:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.99      0.99        88\n",
      "          1       0.96      0.97      0.96        91\n",
      "          2       0.99      0.97      0.98        86\n",
      "          3       0.91      0.92      0.92        91\n",
      "          4       0.99      0.95      0.97        92\n",
      "          5       0.96      0.98      0.97        91\n",
      "          6       0.99      1.00      0.99        91\n",
      "          7       0.99      0.99      0.99        89\n",
      "          8       0.94      0.92      0.93        87\n",
      "          9       0.91      0.93      0.92        92\n",
      "\n",
      "avg / total       0.96      0.96      0.96       898\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[87  0  0  0  1  0  0  0  0  0]\n",
      " [ 0 88  1  0  0  0  0  0  2  0]\n",
      " [ 1  0 83  2  0  0  0  0  0  0]\n",
      " [ 0  0  0 84  0  2  0  1  2  2]\n",
      " [ 0  0  0  0 87  0  0  0  0  5]\n",
      " [ 0  0  0  0  0 89  1  0  0  1]\n",
      " [ 0  0  0  0  0  0 91  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 88  1  0]\n",
      " [ 0  4  0  2  0  0  0  0 80  1]\n",
      " [ 0  0  0  4  0  2  0  0  0 86]]\n",
      "Classification report for k = 3:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.99      0.99        88\n",
      "          1       0.98      0.98      0.98        91\n",
      "          2       0.99      0.94      0.96        86\n",
      "          3       0.91      0.88      0.89        91\n",
      "          4       0.99      0.93      0.96        92\n",
      "          5       0.97      0.97      0.97        91\n",
      "          6       0.99      1.00      0.99        91\n",
      "          7       0.98      0.99      0.98        89\n",
      "          8       0.90      0.95      0.93        87\n",
      "          9       0.89      0.93      0.91        92\n",
      "\n",
      "avg / total       0.96      0.96      0.96       898\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[87  0  0  0  1  0  0  0  0  0]\n",
      " [ 0 89  0  0  0  0  0  0  2  0]\n",
      " [ 1  0 81  4  0  0  0  0  0  0]\n",
      " [ 0  0  0 80  0  1  0  2  5  3]\n",
      " [ 0  0  0  0 86  0  0  0  0  6]\n",
      " [ 0  0  0  0  0 88  1  0  0  2]\n",
      " [ 0  0  0  0  0  0 91  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 88  1  0]\n",
      " [ 0  2  1  1  0  0  0  0 83  0]\n",
      " [ 0  0  0  3  0  2  0  0  1 86]]\n",
      "Classification report for k = 5:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99        88\n",
      "          1       0.96      0.98      0.97        91\n",
      "          2       0.98      0.93      0.95        86\n",
      "          3       0.90      0.88      0.89        91\n",
      "          4       1.00      0.93      0.97        92\n",
      "          5       0.97      0.98      0.97        91\n",
      "          6       0.99      1.00      0.99        91\n",
      "          7       0.95      0.99      0.97        89\n",
      "          8       0.92      0.91      0.91        87\n",
      "          9       0.89      0.92      0.90        92\n",
      "\n",
      "avg / total       0.95      0.95      0.95       898\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[88  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 89  0  0  0  0  0  0  1  1]\n",
      " [ 1  0 80  4  0  0  0  0  0  1]\n",
      " [ 0  0  1 80  0  1  0  3  4  2]\n",
      " [ 0  0  0  0 86  0  0  1  0  5]\n",
      " [ 0  0  0  0  0 89  1  0  0  1]\n",
      " [ 0  0  0  0  0  0 91  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 88  1  0]\n",
      " [ 0  4  1  1  0  0  0  1 79  1]\n",
      " [ 0  0  0  4  0  2  0  0  1 85]]\n",
      "Classification report for k = 100:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.99      0.96        88\n",
      "          1       0.96      0.73      0.83        91\n",
      "          2       0.85      0.86      0.86        86\n",
      "          3       0.72      0.88      0.79        91\n",
      "          4       0.99      0.92      0.96        92\n",
      "          5       0.86      0.82      0.84        91\n",
      "          6       0.96      0.99      0.97        91\n",
      "          7       0.90      0.98      0.94        89\n",
      "          8       0.91      0.74      0.82        87\n",
      "          9       0.76      0.86      0.81        92\n",
      "\n",
      "avg / total       0.88      0.88      0.88       898\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[87  0  0  0  1  0  0  0  0  0]\n",
      " [ 0 66  9  5  0  1  0  0  1  9]\n",
      " [ 1  0 74 11  0  0  0  0  0  0]\n",
      " [ 0  0  0 80  0  2  0  5  3  1]\n",
      " [ 4  0  0  0 85  0  0  2  1  0]\n",
      " [ 0  0  0  2  0 75  3  0  0 11]\n",
      " [ 0  1  0  0  0  0 90  0  0  0]\n",
      " [ 0  0  2  0  0  0  0 87  0  0]\n",
      " [ 0  2  2  7  0  5  1  2 64  4]\n",
      " [ 1  0  0  6  0  4  0  1  1 79]]\n",
      "Classification report for k = 500:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.55      0.98      0.70        88\n",
      "          1       0.86      0.07      0.12        91\n",
      "          2       0.36      0.28      0.32        86\n",
      "          3       0.32      0.88      0.47        91\n",
      "          4       0.74      0.43      0.55        92\n",
      "          5       0.67      0.56      0.61        91\n",
      "          6       0.62      0.90      0.74        91\n",
      "          7       0.89      0.66      0.76        89\n",
      "          8       0.45      0.37      0.41        87\n",
      "          9       0.28      0.05      0.09        92\n",
      "\n",
      "avg / total       0.58      0.52      0.48       898\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[86  0  0  0  1  0  1  0  0  0]\n",
      " [ 3  6 28  9  7  0 13  0 17  8]\n",
      " [ 2  0 24 52  0  0  7  0  1  0]\n",
      " [ 1  0  1 80  0  2  0  3  4  0]\n",
      " [26  0  1  0 40  2 20  2  1  0]\n",
      " [11  0  0 21  0 51  5  0  0  3]\n",
      " [ 8  1  0  0  0  0 82  0  0  0]\n",
      " [ 0  0  3  3  4  4  0 59 16  0]\n",
      " [ 6  0  9 19  2 12  4  1 32  2]\n",
      " [14  0  0 67  0  5  0  1  0  5]]\n"
     ]
    }
   ],
   "source": [
    "# Create a classifier: a support vector classifier\n",
    "#classifier = svm.SVC(gamma=0.001)\n",
    "#classifier = neighbors.KNeighborsClassifier()\n",
    "#classifier = linear_model.LogisticRegression()\n",
    "data_sample = (n_samples/2)\n",
    "\n",
    "dist = [[0 for x in range(2)] for x in range(n_samples/2)]\n",
    "k_neighbors = []\n",
    "k = [1,3,5,100,500]\n",
    "predicted = [[0 for x in range(len(k))] for x in range(n_samples/2)]\n",
    "predicted_k = []\n",
    "data_test = data[n_samples/2 + 1:]\n",
    "expected = digits.target[n_samples / 2 + 1:]\n",
    "print len(expected)\n",
    "for index_sample in range(0, n_samples/2):\n",
    "    \n",
    "    for index in range(0, n_samples/2):\n",
    "        dist[index][0] = numpy.linalg.norm(data[index]-data_test[index_sample])\n",
    "        dist[index][1] = digits.target[index]\n",
    "\n",
    "    dist.sort(key=lambda dist: dist[0])\n",
    "    \n",
    "    #del predicted[:]\n",
    "    \n",
    "    for k_iterator in range(len(k)):\n",
    "        \n",
    "        del k_neighbors[:]\n",
    "    \n",
    "        for index_k in range (k[k_iterator]):\n",
    "            k_neighbors.insert(index_k, dist[index_k][1])\n",
    "    \n",
    "        #predicted.insert(index_sample,Counter(k_neighbors).most_common(1)[0][0])\n",
    "        predicted[index_sample][k_iterator] = Counter(k_neighbors).most_common(1)[0][0]\n",
    "\n",
    "\n",
    "for k_iterator in range(len(k)):\n",
    "    del predicted_k[:]\n",
    "    for index in range (n_samples/2):\n",
    "        predicted_k.insert(index, predicted[index][k_iterator])\n",
    "\n",
    "    print(\"Classification report for k = %s:\\n%s\\n\"\n",
    "                        % (k[k_iterator], metrics.classification_report(expected, predicted_k)))\n",
    "    print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted_k))\n",
    "\n",
    "    \n",
    "# We learn the digits on the first half of the digits\n",
    "#classifier.fit(data[:n_samples / 2], digits.target[:n_samples / 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[86  0  0  0  1  0  1  0  0  0]\n",
      " [ 3  6 28  9  7  0 13  0 17  8]\n",
      " [ 2  0 24 52  0  0  7  0  1  0]\n",
      " [ 1  0  1 80  0  2  0  3  4  0]\n",
      " [26  0  1  0 40  2 20  2  1  0]\n",
      " [11  0  0 21  0 51  5  0  0  3]\n",
      " [ 8  1  0  0  0  0 82  0  0  0]\n",
      " [ 0  0  3  3  4  4  0 59 16  0]\n",
      " [ 6  0  9 19  2 12  4  1 32  2]\n",
      " [14  0  0 67  0  5  0  1  0  5]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted_k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
